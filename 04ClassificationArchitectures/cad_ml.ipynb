{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"rise":{"center":false,"progress":false,"scroll":true,"slidenumber":false,"theme":"while","transition":"none"},"colab":{"name":"cad_ml.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"lxoOSt7SO0mB"},"source":["# Machine Learning with CAD Data"]},{"cell_type":"markdown","metadata":{"id":"_CBkRGPlO0mE"},"source":["Download the ABC dataset from https://deep-geometry.github.io/abc-dataset"]},{"cell_type":"markdown","metadata":{"id":"uRg3dLR6O0mF"},"source":["## Import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E3vVqAkJO4wt","executionInfo":{"status":"ok","timestamp":1615079504888,"user_tz":300,"elapsed":404,"user":{"displayName":"Aditya Balu","photoUrl":"","userId":"00240964590008989444"}},"outputId":"7ead7811-b042-4bab-ee79-352124d04af7"},"source":["! conda install -c conda-forge/label/cf202003 meshplot"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/bin/bash: conda: command not found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":387},"id":"Q_AvbqdEO0mG","executionInfo":{"status":"error","timestamp":1615079370938,"user_tz":300,"elapsed":392,"user":{"displayName":"Aditya Balu","photoUrl":"","userId":"00240964590008989444"}},"outputId":"6e231483-131a-4da1-9f35-8ca61079f90b"},"source":["import meshplot as mp \n","import numpy as np\n","import igl\n","import yaml\n","from yaml import CLoader as Loader\n","\n","import os\n","os.chdir('..')"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-dc1274b4aa34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmeshplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0migl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myaml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'meshplot'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"kZ9H6urUO0mG"},"source":["## Reading CAD Data"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"2OeT6n16O0mH"},"source":["def read_model(obj_path, feat_path):\n","    v, _, n, f, _, ni = igl.read_obj(obj_path)\n","            \n","    with open(feat_path) as fi:\n","        feat = yaml.load(fi, Loader=Loader)\n","    m = {\"vertices\": v, \"face_indices\": f, \"normals\": n, \n","        \"normal_indices\": ni, \"features\": feat}\n","    return m\n","\n","m = read_model(\"data/test_trimesh.obj\", \"data/test_features.yml\")\n","v, f, feat ,= m[\"vertices\"], m[\"face_indices\"], m[\"features\"]\n","print(v.shape, f.shape)\n","print(list(feat.keys()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qRJrTDcoO0mI"},"source":["## CAD Features: Surface Normals"]},{"cell_type":"code","metadata":{"id":"GHUfzy7wO0mI"},"source":["from data.utils import get_averaged_normals\n","\n","# Average normals at vertices with multiple normals\n","av_normals = get_averaged_normals(m)\n","\n","p = mp.plot(v, f, c=np.abs(av_normals), return_plot=True)\n","\n","# Add normals to the plot\n","p.add_lines(v, v + av_normals, shading={\"line_color\": \"black\"});\n","\n","# Determine normals with uniform weighting in libigl\n","normals = igl.per_vertex_normals(v, f)\n","p.add_lines(v, v + normals, shading={\"line_color\": \"red\"});"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jy0KAxLOO0mJ"},"source":["## CAD Features: Sharp Edges/Curves"]},{"cell_type":"code","metadata":{"id":"gMYa0efiO0mJ"},"source":["# Retrieve the sharp features\n","lines = []\n","for i, fe in enumerate(feat[\"curves\"]):\n","    if fe[\"sharp\"]:\n","        for j in range(len(fe[\"vert_indices\"])-1):\n","            lines.append([fe[\"vert_indices\"][j], fe[\"vert_indices\"][j+1]])\n","# Visualize the sharp features            \n","p = mp.plot(v, f)\n","p.add_edges(v, np.array(lines));"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J0jbgktKO0mK"},"source":["## CAD Features: Sharp Edges/Curves"]},{"cell_type":"code","metadata":{"id":"cvUfn-ORO0mK"},"source":["# Retrieve the sharp features\n","v_class = np.zeros((v.shape[0], 1))\n","for i, fe in enumerate(feat[\"curves\"]):\n","    if fe[\"sharp\"]:\n","        v_class[fe[\"vert_indices\"]] = 1\n","        \n","# Visualize the sharp features            \n","mp.plot(v, c=-v_class, shading={\"point_size\": 4.});"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NahaIAHKO0mL"},"source":["## CAD Features: Surface Patch Types"]},{"cell_type":"code","metadata":{"id":"QvSPRH-DO0mL"},"source":["# Retrieve the surface patch types\n","t_map = {\"Plane\": 0, \"Cylinder\": 1,\n","         \"Cone\": 2, \"Sphere\": 3,\n","         \"Torus\": 4, \"Bezier\": 5,\n","         \"BSpline\": 6, \"Revolution\": 7,\n","         \"Extrusion\": 8, \"Other\": 9}\n","\n","c1 = np.zeros(f.shape[0])\n","for fe in feat[\"surfaces\"]:\n","    t = t_map[fe[\"type\"]]\n","    for j in fe[\"face_indices\"]:\n","        c1[j] = t\n","\n","# Visualize the patch types\n","mp.plot(v, f, -c1);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vtPknxCNO0mM"},"source":["## CAD Features: Surface Patch Types"]},{"cell_type":"code","metadata":{"id":"Pl-hnzeyO0mN"},"source":["# Retrieve the surface patch types per vertex\n","c2 = np.zeros(v.shape[0])\n","for fe in feat[\"surfaces\"]:\n","    t = t_map[fe[\"type\"]]\n","    for j in fe[\"vert_indices\"]:\n","        c2[j] = t\n","\n","# Visualize the vertices\n","mp.plot(v, c=-c2, shading={\"point_size\": 4.});"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IX1UoS9LO0mN"},"source":["## Machine Learning Setup"]},{"cell_type":"markdown","metadata":{"id":"Zpeexc_CO0mO"},"source":["## Installation\n","\n","We use [Pytorch](https://pytorch.org/) and [Pytorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) that can be installed as described in their documentation."]},{"cell_type":"markdown","metadata":{"id":"5wiHNneBO0mP"},"source":["## Import"]},{"cell_type":"code","metadata":{"id":"3TT706eyO0mP"},"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Sequential, Dropout, Linear\n","import torch_geometric.transforms as T\n","from torch_geometric.data import DataLoader\n","from torch_geometric.nn import DynamicEdgeConv\n","\n","from data.utils import MLP\n","from data.utils import ABCDataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FQRor6ufO0mQ"},"source":["## Loading the CAD Data"]},{"cell_type":"code","metadata":{"id":"ts8ZRDWVO0mR"},"source":["tf_train = T.Compose([\n","    T.FixedPoints(5000, replace=False),\n","    T.RandomTranslate(0.002),\n","    T.RandomRotate(15, axis=0),\n","    T.RandomRotate(15, axis=1),\n","    T.RandomRotate(15, axis=2)\n","])\n","tf_test = T.Compose([T.FixedPoints(10000, replace=False)])\n","pre = T.NormalizeScale()\n","\n","train_dataset_n = ABCDataset(\"data/ml/ABC\", \"Normals\", True, tf_train, pre)\n","test_dataset_n = ABCDataset(\"data/ml/ABC\", \"Normals\", False, tf_test, pre)\n","train_dataset_e = ABCDataset(\"data/ml/ABC\", \"Edges\", True, tf_train, pre)\n","test_dataset_e = ABCDataset(\"data/ml/ABC\", \"Edges\", False, tf_test, pre)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VPwz0DTzO0mS"},"source":[" ## Statistics and Visualization"]},{"cell_type":"code","metadata":{"id":"3kECX2mCO0mS"},"source":["dataset = test_dataset_e\n","print(\"Number of models:\", len(dataset))\n","print(\"Number of classes:\", dataset.num_classes)\n","\n","counts = [0]*dataset.num_classes\n","total = 0\n","for d in dataset:\n","    y = d.y.numpy()\n","    for i in range(dataset.num_classes):\n","        counts[i] += np.sum(y==i)\n","    total += y.shape[0]\n","\n","for i, c in enumerate(counts):\n","    print(\"%0.2f%% labels are of class %i.\"%(c/total, i))\n","    \n","d = test_dataset_e[3]\n","v = d.pos.numpy()\n","y = d.y.numpy()\n","print(\"Shape of model:\", v.shape)\n","print(\"Shape of labels:\", y.shape)\n","mp.plot(v, c=-y, shading={\"point_size\": 0.15});"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GDUYVGEeO0mS"},"source":["d = test_dataset_n[4]\n","v = d.pos.numpy()\n","y = d.y.numpy()\n","mp.plot(v, c=np.abs(y), shading={\"point_size\": 0.15});"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"52Qk0acoO0mT"},"source":["## Defining the Network (DGCNN)"]},{"cell_type":"code","metadata":{"id":"kAGYp09BO0mT"},"source":["class Net(torch.nn.Module):\n","    def __init__(self, out_channels, k=30, aggr='max', \n","                 typ='Edges'):\n","        super(Net, self).__init__()\n","        self.typ = typ\n","        self.conv1 = DynamicEdgeConv(MLP([2 * 3, 64, 64]), k, aggr)\n","        self.conv2 = DynamicEdgeConv(MLP([2* 64, 64, 64]), k, aggr)\n","        self.conv3 = DynamicEdgeConv(MLP([2* 64, 64, 64]), k, aggr)\n","        self.lin1 = MLP([3 * 64, 1024])\n","\n","        self.mlp = Sequential(MLP([1024, 256]), Dropout(0.5), \n","                              MLP([256, 128]), Dropout(0.5), \n","                              Linear(128, out_channels))\n","\n","    def forward(self, data):\n","        pos, batch = data.pos, data.batch\n","        x1 = self.conv1(pos, batch)\n","        x2 = self.conv2(x1, batch)\n","        x3 = self.conv3(x2, batch)\n","        out = self.lin1(torch.cat([x1, x2, x3], dim=1))\n","        out = self.mlp(out)\n","        if self.typ == \"Edges\" or self.typ == \"Types\":\n","            return F.log_softmax(out, dim=1)\n","        if self.typ == \"Normals\":\n","            return F.normalize(out, p=2, dim=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7MX8MR2WO0mU"},"source":["## Visualizing the Nearest Neighbour Graph"]},{"cell_type":"code","metadata":{"id":"3Dol4ov2O0mV"},"source":["tf_pre = T.Compose([\n","    T.FixedPoints(1000),\n","    T.NormalizeScale(),\n","    T.KNNGraph(k=6)\n","])\n","\n","dataset = ABCDataset(\"data/ml/ABC_graph\", \"Edges\", pre_transform=tf_pre)\n","vd = dataset[0].pos.numpy()\n","p = mp.plot(vd, shading={\"point_size\": 0.15})\n","p.add_edges(vd, dataset[0].edge_index.numpy().T);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mntG8j98O0mV"},"source":["## Defining the Loss Function (Normals)"]},{"cell_type":"code","metadata":{"id":"9oX-WQ3uO0mW"},"source":["class Cosine_Loss(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super(Cosine_Loss,self).__init__()\n","        \n","    def forward(self, x, y):\n","        dotp = torch.mul(x, y).sum(1)\n","        loss = torch.sum(1 - dotp.pow(2)) / x.shape[0]\n","        angle = torch.sum(torch.acos(\n","                torch.clamp(torch.abs(dotp), 0.0, 1.0))) / x.shape[0]\n","        return loss, angle\n","\n","cosine_loss = Cosine_Loss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lH1veYzgO0mW"},"source":["## Defining the Training Procedure"]},{"cell_type":"code","metadata":{"id":"D4UjX3ZQO0mW"},"source":["def train(loader, typ=\"Edges\"):\n","    model.train()\n","\n","    for i, data in enumerate(loader):\n","        total_loss = correct_nodes = total_nodes = 0\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        out = model(data)\n","        \n","        if typ == \"Edges\" or typ == \"Types\":\n","            loss = F.nll_loss(out, data.y)\n","        if typ == \"Normals\":\n","            loss, angle = cosine_loss(out, data.y)\n","            \n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","        \n","        if typ == \"Edges\" or typ == \"Types\":\n","            pred = out.max(dim=1)[1]\n","            correct_nodes += pred.eq(data.y).sum().item()\n","            total_nodes += data.num_nodes\n","            acc = correct_nodes / total_nodes\n","            \n","        if typ == \"Normals\":\n","            acc = angle.item()*180/np.pi\n","        \n","        print('[Train {}/{}] Loss: {:.4f}, Accuracy: {:.4f}'.format(\n","              i + 1, len(loader), total_loss / loader.batch_size, acc)),"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OAeVruUnO0mX"},"source":["## Defining the Testing Procedure"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"rPtDvNCIO0mX"},"source":["def test(loader, typ=\"Edges\"):\n","    model.eval()\n","\n","    correct_nodes = total_nodes = 0\n","    for data in loader:\n","        data = data.to(device)\n","        with torch.no_grad():\n","            out = model(data)\n","            \n","        if typ == \"Edges\" or typ == \"Types\":\n","            pred = out.max(dim=1)[1]\n","            correct_nodes += pred.eq(data.y).sum().item()\n","            total_nodes += data.num_nodes\n","            \n","        if typ == \"Normals\":\n","            _, angle = cosine_loss(out, data.y)\n","            correct_nodes += angle.item() * 180 / np.pi\n","            total_nodes += 1\n","            \n","    return correct_nodes / total_nodes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E6Y51IRdO0mY"},"source":["## Running the Training"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"PmnESSfzO0mZ"},"source":["typ = \"Edges\"\n","\n","if typ == \"Edges\":\n","    train_dataset = train_dataset_e\n","    test_dataset = test_dataset_e\n","\n","if typ == \"Normals\":\n","    train_dataset = train_dataset_n\n","    test_dataset = test_dataset_n\n","\n","train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(train_dataset.num_classes, k=30, typ=typ).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n","                                            step_size=20, gamma=0.8)\n","\n","for epoch in range(1, 3):\n","    train(train_loader, typ=typ)\n","    acc = test(test_loader, typ=typ)\n","    print('Test: {:02d}, Accuracy: {:.4f}'.format(epoch, acc))\n","    torch.save(model.state_dict(), \"%02i_%.2f.dat\"%(epoch, acc))\n","    scheduler.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tT3tZCxIO0mZ"},"source":["## Loading a Pretrained Model - Edges"]},{"cell_type":"code","metadata":{"id":"z_eGG797O0mZ"},"source":["typ = \"Edges\"\n","test_dataset = test_dataset_e\n","state_file = \"Edges_72_0.96.dat\"\n","\n","model = Net(test_dataset.num_classes, k=30, typ=typ)\n","if torch.cuda.is_available():\n","    state = torch.load(\"data/ml/ABC/models/%s\"%state_file)\n","    device = torch.device('cuda')\n","else:\n","    state = torch.load(\"data/ml/ABC/models/%s\"%state_file, \n","                       map_location=torch.device('cpu'))\n","    device = torch.device('cpu')\n","\n","model.load_state_dict(state)\n","model.to(device);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MIn53b9XO0ma"},"source":["## Visualizing the Predicted Results"]},{"cell_type":"code","metadata":{"id":"uhp0vYsUO0ma"},"source":["test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n","loader = iter(test_loader)\n","\n","d = loader.next()\n","with torch.no_grad():\n","    out = model(d.to(device))\n","\n","v = d.pos.cpu().numpy()\n","y = d.y.cpu().numpy()\n","\n","# Calculate accuracy \n","acc = test(test_loader, typ=typ)\n","print('Accuracy: {:.4f}'.format(acc))\n","\n","# Plot groundtruth left, estimation right\n","e = out.max(dim=1)[1].cpu().numpy()\n","p = mp.subplot(v, c=-y, s=[1, 2, 0], shading={\"point_size\":0.15})\n","mp.subplot(v, c=-e, s=[1, 2, 1], data=p, shading={\"point_size\": 0.15});"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f7_cjftLO0mc"},"source":["## Loading a Pretrained Model - Normals"]},{"cell_type":"code","metadata":{"id":"lhYgsLn6O0mf"},"source":["typ = \"Normals\"\n","test_dataset = test_dataset_n\n","state_file = \"Normals_44_12.52.dat\"\n","\n","model = Net(test_dataset.num_classes, k=30, typ=typ)\n","if torch.cuda.is_available():\n","    state = torch.load(\"data/ml/ABC/models/%s\"%state_file)\n","    device = torch.device('cuda')\n","else:\n","    state = torch.load(\"data/ml/ABC/models/%s\"%state_file, \n","                       map_location=torch.device('cpu'))\n","    device = torch.device('cpu')\n","\n","model.load_state_dict(state)\n","model.to(device);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oo2lNKFJO0mg"},"source":["## Visualizing the Predicted Results"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"0CIcie0SO0mh"},"source":["test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n","loader = iter(test_loader)\n","\n","d = loader.next()\n","with torch.no_grad():\n","    out = model(d.to(device))\n","\n","v = d.pos.cpu().numpy()\n","y = d.y.cpu().numpy()\n","\n","# Calculate accuracy\n","_, angle = cosine_loss(out, d.y)\n","print(angle.item() * 180 / np.pi)\n","\n","# Plot groundtruth left, estimation right\n","n = out.cpu().numpy()\n","c1 = np.abs(y)\n","c2 = np.abs(n)\n","p = mp.subplot(v, c=c1, s=[1, 2, 0], shading={\"point_size\":0.15})\n","mp.subplot(v, c=c2, s=[1, 2, 1], data=p, shading={\"point_size\": 0.15})"],"execution_count":null,"outputs":[]}]}